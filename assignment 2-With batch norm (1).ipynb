{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashutosh/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ff9488e409e4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ashutosh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ashutosh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ashutosh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ashutosh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ashutosh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_forward(Z):\n",
    "    A=np.maximum(0,Z)\n",
    "    cache_relu=Z\n",
    "    return A,cache_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA,cache_relu):\n",
    "    g_deriv=1.0*(cache_relu>0)\n",
    "    dZ=dA*g_deriv\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A=1.0/(1.0+np.exp(-Z))\n",
    "    cache_sigmoid=Z\n",
    "    return A,cache_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_back(dA,cache_sigmoid):\n",
    "    g_deriv=cache_sigmoid*(1-cache_sigmoid)\n",
    "    dZ=dA*g_deriv\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 28, 28, 1)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x=mnist.train.images.reshape(55000,28,28,1)\n",
    "y=mnist.train.labels.reshape(55000,10)\n",
    "x=x[:50,:,:]\n",
    "y=y[:50,:]\n",
    "print(x.shape)\n",
    "y=y.T\n",
    "m=y.shape[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchn_forward(A,gamma,beta,eps):\n",
    "    A_mu=np.mean(A,axis=0)\n",
    "    inv_var=1.0/(np.var(A,axis=0))\n",
    "    A_hat=(A-A_mu)/(np.sqrt(1.0/inv_var+eps))\n",
    "    z=gamma*A_hat+beta\n",
    "    cache2=A_mu, inv_var, A_hat, gamma\n",
    "    return z,cache2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchn_backward(dout, cache):\n",
    "    N, D = dout.shape\n",
    "    A_mu, inv_var, A_hat, gamma = cache\n",
    "\n",
    "    inv_var=np.sqrt(inv_var+.001)                                   \n",
    "    dAhat = dout * gamma\n",
    "\n",
    "    dA = (1.0 / N) * inv_var * (N*dAhat - np.sum(dAhat, axis=0) - A_hat*np.sum(dAhat*A_hat, axis=0))\n",
    "    dbeta = np.sum(dout, axis=0)\n",
    "    dgamma = np.sum(A_hat*dout, axis=0)\n",
    "\n",
    "    return dA, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant')\n",
    "     \n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    s =a_slice_prev*W\n",
    "    \n",
    "    Z = np.sum(s)\n",
    "    \n",
    "    Z = Z+np.float(b)\n",
    "    \n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "     \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) =A_prev.shape\n",
    "    \n",
    "     \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    \n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    \n",
    "    n_H = int((n_H_prev-f+2*pad)/stride) +1\n",
    "    n_W = int((n_W_prev-f+2*pad)/stride) +1\n",
    "    \n",
    "     \n",
    "    Z = np.zeros((m,n_H,n_W,n_C))\n",
    "    \n",
    "     \n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                                \n",
    "        a_prev_pad = A_prev_pad[i]                         \n",
    "        for h in range(n_H):                          \n",
    "            for w in range(n_W):                       \n",
    "                for c in range(n_C):                   \n",
    "                     \n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start+f\n",
    "                    horiz_start = w*stride \n",
    "                    horiz_end = horiz_start+f\n",
    "                    \n",
    "                     \n",
    "                    a_slice_prev =a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    \n",
    "                    \n",
    "                    Z[i, h, w, c] =conv_single_step(a_slice_prev, W[:,:,:,c], b[:,:,:,c])\n",
    "                                        \n",
    "     \n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    A,cache_relu=relu_forward(Z)\n",
    "    \n",
    "    \n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return A, cache,cache_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "     \n",
    "     \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "     \n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "     \n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "     \n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "     \n",
    "    for i in range(m):                          \n",
    "        for h in range(n_H):                      \n",
    "            for w in range(n_W):                  \n",
    "                for c in range (n_C):             \n",
    "                    \n",
    "                     \n",
    "                    vert_start =h*stride\n",
    "                    vert_end = vert_start+f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start+f\n",
    "                    \n",
    "                    \n",
    "                    a_prev_slice = A_prev[i,vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                    \n",
    "                     \n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "     \n",
    "    \n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    \n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(A_prev,w,b,gamma,beta,eps):\n",
    "    (m,hw) = A_prev.shape\n",
    "\n",
    "     \n",
    "    Z=np.dot(w,A_prev)+b\n",
    "    \n",
    "    ZT,cache2=batchn_forward(Z,gamma,beta,eps)\n",
    "    cache_fc=(A_prev,w,b)\n",
    "    return ZT,cache_fc,cache2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    Z_exp=np.exp(Z)\n",
    "    Z_sum=np.sum(Z_exp,axis=0)\n",
    "    Z_sf=Z_exp/Z_sum\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Z_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def loss(predicted,y):\n",
    "        m=y.shape[1]\n",
    "        loss=-np.log(predicted)*y\n",
    "         \n",
    "        loss=(np.sum(loss))\n",
    "          \n",
    "        loss=loss/m\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_backward(dZT,cache,cache2):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dZ, dgamma, dbeta=batchn_backward(dZT, cache2)\n",
    "     \n",
    "    dW = 1.0/m*(np.dot(dZ,A_prev.T))\n",
    "    db = 1.0/m*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev,dW,db,dgamma,dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "     \n",
    "    \n",
    "    \n",
    "    mask = (x==np.max(x))\n",
    "     \n",
    "    \n",
    "    return mask\n",
    "\n",
    "def distribute_value(dz, shape):\n",
    "     \n",
    "    \n",
    "     \n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    \n",
    "    average = n_H*n_W\n",
    "    \n",
    "     \n",
    "    a = np.ones(shape)*dz/average\n",
    "     \n",
    "    return a\n",
    "\n",
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "     \n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "     \n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "     \n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    \n",
    "    for i in range(m):                        \n",
    "        \n",
    "         \n",
    "        a_prev = A_prev[i]\n",
    "        \n",
    "        for h in range(n_H):                   \n",
    "            for w in range(n_W):                \n",
    "                for c in range(n_C):            \n",
    "                    \n",
    "                    \n",
    "                    vert_start = h\n",
    "                    vert_end = h+f\n",
    "                    horiz_start = w\n",
    "                    horiz_end = w+f\n",
    "                    \n",
    "                    \n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                         \n",
    "                        a_prev_slice = a_prev[vert_start:vert_end,horiz_start:horiz_end,c]\n",
    "                        \n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                         \n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask*dA[i,h,w, c]\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                         \n",
    "                        da = dA[i,h,w,c]\n",
    "                         \n",
    "                        shape = (f,f)\n",
    "                         \n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
    "                        \n",
    "     \n",
    "    \n",
    "    \n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " def conv_backward(dA, cache,cache_relu):\n",
    "     \n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "     \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "     \n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    dZ=relu_backward(dA,cache_relu)\n",
    "     \n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "     \n",
    "    dA_prev = np.zeros(A_prev.shape)                           \n",
    "    dW = np.zeros(W.shape)\n",
    "    db = np.zeros(b.shape)\n",
    "\n",
    "     \n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):                        \n",
    "        \n",
    "         \n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        da_prev_pad = dA_prev_pad[i]\n",
    "        \n",
    "        for h in range(n_H):                    \n",
    "            for w in range(n_W):                \n",
    "                for c in range(n_C):            \n",
    "                    \n",
    "                     \n",
    "                    vert_start = h*pad\n",
    "                    vert_end = h*pad+f\n",
    "                    horiz_start = w*pad\n",
    "                    horiz_end = w*pad+f\n",
    "                    \n",
    "                     \n",
    "                    a_slice = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
    "                    \n",
    "                     \n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "        \n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 28, 28, 1)\n",
      "(50, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "A_0=x\n",
    "print(A_0.shape)\n",
    "W_1=np.random.randn(3,3,1,3)*0.01\n",
    "b_1=np.random.randn(1,1,1,3)\n",
    "A_1,cache_1,cache_relu1=conv_forward(A_0, W_1, b_1, hparameters={\"stride\":1,\"pad\":1})\n",
    "print(A_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "W_2=np.random.randn(3,3,3,3)*0.01\n",
    "b_2=np.random.randn(1,1,1,3)\n",
    "A_2,cache_2,cache_relu2=conv_forward(A_1, W_2, b_2, hparameters={\"stride\":1,\"pad\":1})\n",
    "print(A_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 14, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "A_3, cache_2p= pool_forward(A_2, hparameters={\"f\":2,\"stride\":2}, mode = \"max\")\n",
    "print(A_3.shape)\n",
    "A_3=(A_3.reshape(50,588)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_3=np.random.randn(10,588)*0.01\n",
    "b_3=np.random.randn(10,1)\n",
    "gamma=np.random.rand(10,1)\n",
    "beta=np.random.rand(10,1)\n",
    "eps=.0001\n",
    "ZT_3,cache_3,cache2=fc(A_3, W_3, b_3,gamma,beta,eps)\n",
    "\n",
    " \n",
    "A_4=softmax(ZT_3)\n",
    "dZT_3=A_4-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs.append(loss(A_4, y))\n",
    "temp_cost=loss(A_4, y)\n",
    "change=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch completed and cost is 1.399778545\n",
      "2 epoch completed and cost is 1.3902417103\n",
      "3 epoch completed and cost is 1.38577701756\n",
      "4 epoch completed and cost is 1.3839108493\n",
      "5 epoch completed and cost is 1.38273330417\n",
      "6 epoch completed and cost is 1.38168274875\n",
      "7 epoch completed and cost is 1.38067585624\n",
      "8 epoch completed and cost is 1.37970275887\n",
      "9 epoch completed and cost is 1.37876132556\n",
      "10 epoch completed and cost is 1.37785040008\n",
      "11 epoch completed and cost is 1.37696907641\n",
      "12 epoch completed and cost is 1.37611650866\n",
      "13 epoch completed and cost is 1.37529179017\n",
      "14 epoch completed and cost is 1.37449386668\n",
      "15 epoch completed and cost is 1.37372148432\n",
      "16 epoch completed and cost is 1.37297317568\n",
      "17 epoch completed and cost is 1.37224728373\n",
      "18 epoch completed and cost is 1.3715420182\n",
      "19 epoch completed and cost is 1.37085553335\n",
      "20 epoch completed and cost is 1.37018601283\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    dA_3,dW_3,db_3,dgamma_3,dbeta_3=fc_backward(dZT_3, cache_3,cache2)\n",
    "    \n",
    "    dA_3=dA_3.T\n",
    "    dA_3=dA_3.reshape(50,14,14,3)\n",
    "    dA_2=pool_backward(dA_3, cache_2p, mode = \"max\")\n",
    "    \n",
    "    dZ_1,dW_2,db_2=conv_backward(dA_2, cache_2,cache_relu2)\n",
    "    dA_1,dW_1,db_1=conv_backward(dZ_1, cache_1,cache_relu1)\n",
    "    learning_rate=1\n",
    "    W_1=W_1-learning_rate*dW_1\n",
    "    W_2=W_2-learning_rate*dW_2\n",
    "    W_3=W_3-learning_rate*dW_3\n",
    "    \n",
    "    b_1=b_1-learning_rate*db_1\n",
    "    b_2=b_2-learning_rate*db_2\n",
    "    b_3=b_3-learning_rate*db_3\n",
    "    gamma=gamma-learning_rate*dgamma_3\n",
    "    beta=beta-learning_rate*dbeta_3\n",
    "    A_1,cache_1,cache_relu1=conv_forward(A_0, W_1, b_1, hparameters={\"stride\":1,\"pad\":1})\n",
    "    A_2,cache_2,cache_relu2=conv_forward(A_1, W_2, b_2, hparameters={\"stride\":1,\"pad\":1})\n",
    "    A_3, cache_2p= pool_forward(A_1, hparameters={\"f\":2,\"stride\":2}, mode = \"max\")\n",
    "    A_3=(A_3.reshape(50,588)).T\n",
    "    Z_3,cache_3,cache2=fc(A_3, W_3, b_3,gamma,beta,eps)\n",
    "    \n",
    "    \n",
    " \n",
    "    A_4=softmax(Z_3)\n",
    "    dZT_3=A_4-y\n",
    "    cost=loss(A_4, y)\n",
    "    costs.append(cost)\n",
    "    change=temp_cost-cost\n",
    "    temp_cost=cost\n",
    "    \n",
    "    print(\"{} epoch completed and cost is {}\".format(i+1,cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff704d24c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4149256561787578, 1.3997785449976825, 1.3902417103012854, 1.3857770175623423, 1.383910849296749, 1.3827333041722125, 1.3816827487544265, 1.380675856239755, 1.3797027588705846, 1.378761325562281, 1.377850400081751, 1.3769690764124232, 1.3761165086603722, 1.3752917901730535, 1.374493866677207, 1.3737214843159584, 1.3729731756781798, 1.3722472837345139, 1.3715420182011386, 1.3708555333478203, 1.370186012834592]\n"
     ]
    }
   ],
   "source": [
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
